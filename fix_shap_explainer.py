#!/usr/bin/env python3
"""
Fix SHAP explainer for the current model
"""

import joblib
import numpy as np
import pandas as pd
import shap
import os

def regenerate_shap_explainer():
    """Regenerate SHAP explainer for the current model"""
    
    # Change to M directory where model files are located
    os.chdir('M')
    
    print("ğŸ”§ Regenerating SHAP explainer...")
    
    # Load the current model
    model_files = [
        'optimized_xgboost_sepsis_model.pkl',
        'enhanced_xgboost_sepsis_model.pkl',
        'xgboost_sepsis_model.pkl'
    ]
    
    model = None
    model_type = None
    
    for model_file in model_files:
        if os.path.exists(model_file):
            try:
                model = joblib.load(model_file)
                model_type = model_file.replace('_xgboost_sepsis_model.pkl', '')
                print(f"âœ… Loaded model: {model_file}")
                break
            except Exception as e:
                print(f"âŒ Failed to load {model_file}: {e}")
                continue
    
    if model is None:
        print("âŒ No model found!")
        return False
    
    # Load feature names
    feature_files = [
        f'{model_type}_feature_names.pkl',
        'feature_names.pkl'
    ]
    
    feature_names = None
    for feature_file in feature_files:
        if os.path.exists(feature_file):
            try:
                feature_names = joblib.load(feature_file)
                print(f"âœ… Loaded feature names: {feature_file} ({len(feature_names)} features)")
                break
            except Exception as e:
                print(f"âŒ Failed to load {feature_file}: {e}")
                continue
    
    if feature_names is None:
        print("âŒ No feature names found!")
        return False
    
    # Load scaler
    scaler_files = [
        f'{model_type}_scaler.pkl',
        'scaler.pkl'
    ]
    
    scaler = None
    for scaler_file in scaler_files:
        if os.path.exists(scaler_file):
            try:
                scaler = joblib.load(scaler_file)
                print(f"âœ… Loaded scaler: {scaler_file}")
                break
            except Exception as e:
                print(f"âŒ Failed to load {scaler_file}: {e}")
                continue
    
    if scaler is None:
        print("âŒ No scaler found!")
        return False
    
    # Load training data for SHAP background
    try:
        X_train_files = [
            'X_train_scaled.npy',
            'X_test_scaled.npy'  # Fallback
        ]
        
        X_background = None
        for X_file in X_train_files:
            if os.path.exists(X_file):
                X_background = np.load(X_file)
                print(f"âœ… Loaded background data: {X_file} {X_background.shape}")
                break
        
        if X_background is None:
            print("âš ï¸  No training data found, creating synthetic background...")
            # Create synthetic background data
            n_samples = 100
            n_features = len(feature_names)
            X_background = np.random.normal(0, 1, (n_samples, n_features))
            print(f"âœ… Created synthetic background: {X_background.shape}")
        
        # Use a subset for efficiency
        if X_background.shape[0] > 100:
            indices = np.random.choice(X_background.shape[0], 100, replace=False)
            X_background = X_background[indices]
            print(f"âœ… Using background subset: {X_background.shape}")
        
    except Exception as e:
        print(f"âŒ Error loading background data: {e}")
        return False
    
    # Create SHAP explainer
    try:
        print("ğŸ”„ Creating SHAP TreeExplainer...")
        explainer = shap.TreeExplainer(model, X_background)
        print("âœ… SHAP TreeExplainer created successfully")
        
        # Test the explainer with a sample
        print("ğŸ§ª Testing SHAP explainer...")
        test_sample = X_background[:1]  # Use first sample as test
        shap_values = explainer.shap_values(test_sample)
        
        if isinstance(shap_values, list):
            shap_values = shap_values[1]  # For binary classification, use positive class
        
        print(f"âœ… SHAP test successful: {shap_values.shape}")
        print(f"   Sample SHAP values: {shap_values[0][:5]}...")
        
        # Save the explainer
        explainer_filename = f'{model_type}_shap_explainer.pkl'
        joblib.dump(explainer, explainer_filename)
        print(f"âœ… SHAP explainer saved as: {explainer_filename}")
        
        # Also save as default name
        joblib.dump(explainer, 'shap_explainer.pkl')
        print("âœ… SHAP explainer saved as: shap_explainer.pkl")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error creating SHAP explainer: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸ”§ SHAP Explainer Fix Tool")
    print("=" * 40)
    
    success = regenerate_shap_explainer()
    
    print("\n" + "=" * 40)
    if success:
        print("âœ… SHAP explainer regenerated successfully!")
        print("ğŸ”„ Please restart the API server to load the new explainer.")
    else:
        print("âŒ Failed to regenerate SHAP explainer.")
        print("ğŸ’¡ Check the error messages above for details.")